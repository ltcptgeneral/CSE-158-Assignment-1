{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data into dataset array\n",
    "import gzip\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readJSON(path):\n",
    "    f = gzip.open(path, 'rt', encoding=\"utf-8\")\n",
    "    f.readline()\n",
    "    for l in f:\n",
    "        d = eval(l)\n",
    "        u = d['userID']\n",
    "        g = d['gameID']\n",
    "        yield u,g,d\n",
    "\n",
    "dataset = []\n",
    "for l in readJSON(\"train.json.gz\"):\n",
    "    dataset.append(l)\n",
    "\n",
    "for user,game,review in dataset:\n",
    "    review[\"played\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#train, valid = train_test_split(dataset, train_size=165000, random_state=0)\n",
    "train = dataset[:165000]\n",
    "valid = dataset[165000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get negative labels in vaidation\n",
    "import random\n",
    "\n",
    "def get_balanced_set(dataset, s):\n",
    "    all_games = set()\n",
    "    user_played = defaultdict(set)\n",
    "\n",
    "    for user,game,review in dataset:\n",
    "        all_games.add(review[\"gameID\"])\n",
    "        user_played[review[\"userID\"]].add(review[\"gameID\"])\n",
    "\n",
    "    negative = []\n",
    "\n",
    "    for user,game,review in s:\n",
    "        not_played = all_games - user_played[user]\n",
    "        new_game = random.choice(tuple(not_played))\n",
    "        negative.append((user, new_game, {\"played\": 0}))\n",
    "\n",
    "    return s + negative\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writePredictions(infile, outfile, model):\n",
    "    with open(outfile, 'w') as predictions:\n",
    "        for l in open(infile):\n",
    "            if l.startswith(\"userID\"):\n",
    "                predictions.write(l)\n",
    "                continue\n",
    "            u,g = l.strip().split(',')\n",
    "            \n",
    "            pred = model.predict(u,g)\n",
    "            \n",
    "            _ = predictions.write(u + ',' + g + ',' + str(pred) + '\\n')\n",
    "\n",
    "        predictions.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BPRbatch(tf.keras.Model):\n",
    "    def __init__(self, K, lamb, itemIDs, userIDs):\n",
    "        super(BPRbatch, self).__init__()\n",
    "        # Initialize variables\n",
    "        self.betaI = tf.Variable(tf.random.normal([len(itemIDs)],stddev=0.001))\n",
    "        self.gammaU = tf.Variable(tf.random.normal([len(userIDs),K],stddev=0.001))\n",
    "        self.gammaI = tf.Variable(tf.random.normal([len(itemIDs),K],stddev=0.001))\n",
    "        # Regularization coefficient\n",
    "        self.lamb = lamb\n",
    "\n",
    "    # Prediction for a single instance\n",
    "    def predict(self, u, i):\n",
    "        p = self.betaI[i] + tf.tensordot(self.gammaU[u], self.gammaI[i], 1)\n",
    "        return p\n",
    "\n",
    "    # Regularizer\n",
    "    def reg(self):\n",
    "        return self.lamb * (tf.nn.l2_loss(self.betaI) +\\\n",
    "                            tf.nn.l2_loss(self.gammaU) +\\\n",
    "                            tf.nn.l2_loss(self.gammaI))\n",
    "    \n",
    "    def score(self, sampleU, sampleI):\n",
    "        u = tf.convert_to_tensor(sampleU, dtype=tf.int32)\n",
    "        i = tf.convert_to_tensor(sampleI, dtype=tf.int32)\n",
    "        beta_i = tf.nn.embedding_lookup(self.betaI, i)\n",
    "        gamma_u = tf.nn.embedding_lookup(self.gammaU, u)\n",
    "        gamma_i = tf.nn.embedding_lookup(self.gammaI, i)\n",
    "        x_ui = beta_i + tf.reduce_sum(tf.multiply(gamma_u, gamma_i), 1)\n",
    "        return x_ui\n",
    "\n",
    "    def call(self, sampleU, sampleI, sampleJ):\n",
    "        x_ui = self.score(sampleU, sampleI)\n",
    "        x_uj = self.score(sampleU, sampleJ)\n",
    "        return -tf.reduce_mean(tf.math.log(tf.math.sigmoid(x_ui - x_uj)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Play Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlayPredictor:\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, data, threshold=0.6, K=5, iters=100): # data is an array of (user, game, review) tuples\n",
    "        self.topGames = self.getTopGames(threshold)\n",
    "\n",
    "        self.userIDs = {}\n",
    "        self.itemIDs = {}\n",
    "        interactions = []\n",
    "\n",
    "        for u,i,r in data:\n",
    "            if not u in self.userIDs: self.userIDs[u] = len(self.userIDs)\n",
    "            if not i in self.itemIDs: self.itemIDs[i] = len(self.itemIDs)\n",
    "            interactions.append((u,i,r[\"played\"]))\n",
    "        \n",
    "        items = list(self.itemIDs.keys())\n",
    "        \n",
    "        itemsPerUser = defaultdict(list)\n",
    "        usersPerItem = defaultdict(list)\n",
    "        for u,i,r in interactions:\n",
    "            itemsPerUser[u].append(i)\n",
    "            usersPerItem[i].append(u)\n",
    "\n",
    "        def trainingStepBPR(model, interactions):\n",
    "            Nsamples = 50000\n",
    "            with tf.GradientTape() as tape:\n",
    "                sampleU, sampleI, sampleJ = [], [], []\n",
    "                for _ in range(Nsamples):\n",
    "                    u,i,_ = random.choice(interactions) # positive sample\n",
    "                    j = random.choice(items) # negative sample\n",
    "                    while j in itemsPerUser[u]:\n",
    "                        j = random.choice(items)\n",
    "                    sampleU.append(self.userIDs[u])\n",
    "                    sampleI.append(self.itemIDs[i])\n",
    "                    sampleJ.append(self.itemIDs[j])\n",
    "\n",
    "                loss = model(sampleU,sampleI,sampleJ)\n",
    "                loss += model.reg()\n",
    "            gradients = tape.gradient(loss, model.trainable_variables)\n",
    "            optimizer.apply_gradients((grad, var) for\n",
    "                                    (grad, var) in zip(gradients, model.trainable_variables)\n",
    "                                    if grad is not None)\n",
    "            return loss.numpy()\n",
    "        \n",
    "        optimizer = tf.keras.optimizers.Adam(0.1)\n",
    "        self.modelBPR = BPRbatch(K, 0.00001, self.itemIDs, self.userIDs)\n",
    "\n",
    "        for i in range(iters):\n",
    "            obj = trainingStepBPR(self.modelBPR, interactions)\n",
    "            if (i % 10 == 9): print(\"iteration \" + str(i+1) + \", objective = \" + str(obj))\n",
    "            \n",
    "    def predict(self, user, game, threshold=0.5):\n",
    "        if user in self.userIDs and game in self.itemIDs:\n",
    "            pred = self.modelBPR.predict(self.userIDs[user], self.itemIDs[game]).numpy()\n",
    "            return int(pred > threshold)\n",
    "        else:\n",
    "            return int(game in self.topGames)\n",
    "\n",
    "    def getTopGames (self, threshold):\n",
    "        gameCount = defaultdict(int)\n",
    "        totalPlayed = 0\n",
    "\n",
    "        for user,game,_ in readJSON(\"train.json.gz\"):\n",
    "            gameCount[game] += 1\n",
    "            totalPlayed += 1\n",
    "\n",
    "        mostPopular = [(gameCount[x], x) for x in gameCount]\n",
    "        mostPopular.sort()\n",
    "        mostPopular.reverse()\n",
    "\n",
    "        return1 = set()\n",
    "        count = 0\n",
    "        for ic, i in mostPopular:\n",
    "            count += ic\n",
    "            return1.add(i)\n",
    "            if count > totalPlayed * threshold: break\n",
    "        return return1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 10, objective = 0.51180786\n",
      "iteration 20, objective = 0.48082852\n",
      "iteration 30, objective = 0.47100148\n",
      "iteration 40, objective = 0.45862892\n",
      "iteration 50, objective = 0.45290428\n",
      "iteration 60, objective = 0.44695023\n",
      "iteration 70, objective = 0.4453482\n",
      "iteration 80, objective = 0.444919\n",
      "iteration 90, objective = 0.4451945\n",
      "iteration 100, objective = 0.44311014\n",
      "iteration 110, objective = 0.44101325\n",
      "iteration 120, objective = 0.43727913\n",
      "iteration 130, objective = 0.43938398\n",
      "iteration 140, objective = 0.43788543\n",
      "iteration 150, objective = 0.43573555\n",
      "iteration 160, objective = 0.4379884\n",
      "iteration 170, objective = 0.43852594\n",
      "iteration 180, objective = 0.4391472\n",
      "iteration 190, objective = 0.4318109\n",
      "iteration 200, objective = 0.4389726\n",
      "PlayPredictor accuracy:  0.7234723472347235\n"
     ]
    }
   ],
   "source": [
    "model = PlayPredictor()\n",
    "model.fit(train, K=6, iters=200)\n",
    "\n",
    "error = 0\n",
    "balanced_valid = get_balanced_set(dataset, valid)\n",
    "for user, game, review in balanced_valid:\n",
    "    pred = model.predict(user, game, threshold=0.5)\n",
    "    if pred != review[\"played\"]:\n",
    "        error += 1\n",
    "\n",
    "print(f\"PlayPredictor accuracy: \", 1 - error / len(balanced_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "writePredictions(\"pairs_Played.csv\", \"predictions_Played.csv\", model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import copy\n",
    "\n",
    "class TimePredictor:\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, data, l=5.0, iters=200): # data is an array of (user, game, review) tuples\n",
    "        reviewsPerUser = defaultdict(list)\n",
    "        reviewsPerItem = defaultdict(list)\n",
    "\n",
    "        globalAverage = 0\n",
    "\n",
    "        for user, game, review in data:\n",
    "            reviewsPerUser[user].append(review)\n",
    "            reviewsPerItem[game].append(review)\n",
    "\n",
    "            globalAverage += review[\"hours_transformed\"]\n",
    "\n",
    "        globalAverage /= len(data)\n",
    "\n",
    "        betaU = {}\n",
    "        betaI = {}\n",
    "        for u in reviewsPerUser:\n",
    "            reviews = [r[\"hours_transformed\"] for r in reviewsPerUser[u]]\n",
    "            betaU[u] = np.mean(reviews)\n",
    "\n",
    "        for g in reviewsPerItem:\n",
    "            reviews = [r[\"hours_transformed\"] for r in reviewsPerItem[g]]\n",
    "            betaI[g] = np.mean(reviews)\n",
    "\n",
    "        alpha = globalAverage # Could initialize anywhere, this is a guess\n",
    "\n",
    "        for i in range(iters):\n",
    "\n",
    "            newAlpha = 0\n",
    "            for user,game,review in data:\n",
    "                newAlpha += review[\"hours_transformed\"] - (betaU[user] + betaI[game])\n",
    "            alpha = newAlpha / len(data)\n",
    "\n",
    "            for user in reviewsPerUser:\n",
    "                bu = 0\n",
    "                for review in reviewsPerUser[user]:\n",
    "                    item = review[\"gameID\"]\n",
    "                    bu += review[\"hours_transformed\"] - (alpha + betaI[item])\n",
    "                betaU[user] = bu / (l + len(reviewsPerUser[user]))\n",
    "            \n",
    "            for item in reviewsPerItem:\n",
    "                bi = 0\n",
    "                for review in reviewsPerItem[item]:\n",
    "                    user = review[\"userID\"]\n",
    "                    bi += review[\"hours_transformed\"] - (alpha + betaU[user])\n",
    "                betaI[item] = bi / (l + len(reviewsPerItem[item]))\n",
    "        \n",
    "        self.alpha = alpha\n",
    "        self.betaU = betaU\n",
    "        self.betaI = betaI\n",
    "\n",
    "    def predict(self, user, game):\n",
    "        bu = 0\n",
    "        bi = 0\n",
    "\n",
    "        if user in self.betaU:\n",
    "            bu = self.betaU[user]\n",
    "        \n",
    "        if game in self.betaI:\n",
    "            bi = self.betaI[game]\n",
    "\n",
    "        return self.alpha + bu + bi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimePredictor MSE: 2.990628028380304\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def MSE(y, ypred):\n",
    "    return mean_squared_error(y, ypred)\n",
    "\n",
    "model = TimePredictor()\n",
    "model.fit(train)\n",
    "\n",
    "y = []\n",
    "y_pred = []\n",
    "for user, game, review in valid:\n",
    "    y_pred.append(model.predict(user, game))\n",
    "    y.append(review[\"hours_transformed\"])\n",
    "\n",
    "print(f\"TimePredictor MSE: {MSE(y, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "writePredictions(\"pairs_Hours.csv\", \"predictions_Hours.csv\", model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
